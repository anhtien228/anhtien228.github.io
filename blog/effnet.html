<!DOCTYPE html>
<html lang="en" class="bg-obsidian js">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="initial-scale=1, width=device-width">
    <link rel="stylesheet" href="../static/css/style.css">
    <link rel="stylesheet" href="../static/css/blog.css">
    <link rel="icon" type="image/png" sizes="32x32" href="../assets/pfp.png">
    <!-- Bootstrap -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0-beta1/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-0evHe/X+R7YkIZDRvuzKMRqM+OrBnVFBL6DOitfPri4tjfHxaWutUpFmBp4vmVor" crossorigin="anonymous">
    <title>Deep Learning: EfficientNetV2 Model in Computer Vision</title>
    <meta name="robots" content="index,follow">
    <meta name="description"
        content="Doan Anh Tien | A blog about the concept of EfficientNetV2 architecture. You will gain an understanding of this deep neural network, its performance and applications in computer vision field.">
    <meta property="author" content="Doan Anh Tien">
    <meta property="og:site_name" content="Doan Anh Tien's Blog">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Deep Learning: EfficientNetV2 Model in Computer Vision">
    <meta property="og:description"
        content="Doan Anh Tien | A blog about the concept of EfficientNetV2 architecture. You will gain an understanding of this deep neural network, its performance and applications in computer vision field.">
    <!-- JQuery -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
    <script>
        MathJax = {
          tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']]
          },
          color: '#dcf6ff'
        };
    </script>
    <script id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>
</head>

<body class="overflow-x-hidden bg-obsidian">
    <div class="f-main-container">
        <main class="f-standard-container has-newsletter js-standard-container font-gilroy" role="main">
            <div class="f-standard-wrapper in-post">
                <article class="f-article js-article">
                    <header class="f-article-header fadeinDown">
                        <h1 class="f-article-header__title js-article-title font-semibold">
                                Deep Learning: EfficientNetV2 Model in Computer Vision
                            </h1>
                            <p class=" f-article-header__excerpt in-post">
                                This blog provides to you the concept and the architecture of EfficientNetV2 family model. You will gain an
                                understanding of this deep neural network, its performance and applications in computer vision field.
                            </p>
                            <p class="f-article-header__time">
                                <span>February 7, 2022</span>
                                <span>&nbsp; • &nbsp;</span>
                                <span>15 min read</span>
                            </p>
                            <div class="f-article-header__author">
                                <a href="../index.html" class="f-avatar in-article-header "
                                    aria-label="Samhita Alla's profile'" aria-haspopup="false">
                                    <img alt="" class="lazy loaded rounded-full" width="45" height="45"
                                        data-ll-status="loaded" src="../assets/pfp.png">
                                </a>
                                <span class="ms-4">
                                    By
                                    <a href="../index.html" class="link link-underline">Doan Anh Tien</a>
                                </span>
                            </div>
                    </header>
                    <div class="f-article-content js-article-content fadeinRight text-space">
                        <h2 id="introduction" class="font-semibold">Introduction</h2>
                        <p> 
                            There is no doubt that machine learning is becoming well-known these days not only to
                            developer, but also common businesses due to its simplicity, all thanks to the efforts of
                            the creator to make the libraries, tools and framework to be more concise and user-friendly.
                        </p>
                        <p>
                            As as student that major in Computer Science and Engineering, my interests in Data Science and ML has been charmed
                            with the appearance of the Machine Learning Engineer course by DIVE INTO CODE. Being a learner for more than one
                            year, the course has convey a lot of useful theories and practical problem to brush my skills. This blog is
                            created to demonstrate the final assignment for my graduation at DIVE INTO CODE, and everything here is served to
                            describe my work in details.
                        </p>
                        <p>
                            For the project, I chose to participate to a contest called 
                            <a href="https://challenge.zalo.ai" class="text-cyan link link-underline"
                            rel="noopener noreferrer" target="_blank">Zalo AI Challenge 2021</a>
                            , the fourth-year of an annual
                            online competition for Vietnam’s AI engineers to explore AI technologies and impact life in exciting new ways. In
                            2021, the competition consist of 3 main problems, and my work is related to one of them, the 
                            <a href="https://challenge.zalo.ai" class="text-cyan link link-underline"
                            rel="noopener noreferrer" target="_blank">5K Compliance</a>
                            .
                        </p>
                        <h2 id="overview" class="font-semibold">Competition overview</h2>
                        <p>
                            In this section, I will briefly explain about the meaning of the name, the description and rules of the challenge,
                            and the dataset that need to be interpreted on.
                        </p>
                        <p>
                            During the Covid-19 outbreak, the Vietnamese government pushed the "5K" public health safety message. In the
                            message, masking and keeping a safe distance are two key rules that have been shown to be extremely successful in
                            preventing people from contracting or spreading the virus. Enforcing these principles on a large scale is where
                            technology may help. In this challenge, you will create algorithm to detect whether or not a person or group of
                            individuals in a picture adhere to the <b><u>mask</u></b> and <b><u>distance</u></b> standards.
                        </p>
                        <h4 id="rules" class="text-center link link-underline" style="width: fit-content; cursor: auto">
                            <b>Basic rules</b>
                        </h4>
                        <p>
                            We are given the dataset contains images of people either wearing mask or not and they are standing either close of
                            far from each other. Our mission is to predict whether the formation of these people adhere the 5k standard.
                        </p>
                        <p>
                            The 5k standard is also based on the two conditions, mask (0 = not wearing, 1 = wearing) and distancing (0 = too
                            close, 1 = far enough). People that adhere the 5k standard will not likely to expose the virus to each other in case
                            they did caught it before, and it is to prevent the spread of the COVID-19 pandamic through people interactions.
                        </p>
                        <div class="d-flex flex-row gap-sm-4">
                            <figure class="kg-card kg-image-card kg-card-hascaption">
                                <img src="https://drive.google.com/uc?id=14aCQhbeEymqpQLMmuTXrPDqk3LIVE_lB"
                                class="kg-image lightense-target" alt="Dataset sample" loading="lazy">
                                <figcaption>Dataset sample 1</figcaption>
                            </figure>
                            <figure class="kg-card kg-image-card kg-card-hascaption">
                                <img src="https://drive.google.com/uc?id=1_vlmEjXEdU-TRnkKu_DREYuJUlUgfBLW"
                                class="kg-image lightense-target" alt="Dataset sample" loading="lazy">
                                <figcaption>Dataset sample 2</figcaption>
                            </figure>
                        </div>

                        <h2 id="background-method" class="font-semibold">Background & Methodologies</h2>
                        <p>
                            In this section, we will have a discussion about the methodologies, models that our project has implemented and
                            applied. This will enable reader to understand the mechanism behind them and how useful they are in this specific
                            image detection field. The first part will mainly focus on the EfficientNet baseline model first.
                        </p>
                        <h3 id="efficientnet" class="font-semibold">EfficientNet</h3>
                        <p>
                            Convolutional Neural Networks (ConvNets) are frequently constructed with a limited resource budget and then scaled
                            up for improved accuracy as more resources become available.
                            <a class="text-cyan link link-underline" href="https://arxiv.org/abs/2104.00298"
                            rel="noopener noreferrer" target="_blank">Creators of EfficientNet</a>
                            has conducted a research
                            paper, in which they study model scaling and learn that better accuracy or resources efficiency can be reached if we
                            could balance the network depth, width, and resolution. They proposed a new scaling method uses a simple but very
                            effective compound scaling method to scale all depth/width/resolution dimensions equally.
                        </p>
                        <p>
                            The researchers also design a family of models to evaluate its performance and size. The dataset used in their study
                            is <a class="text-cyan link link-underline" href="https://www.image-net.org"
                            rel="noopener noreferrer" target="_blank">ImageNet</a>
                            which is a large database of annotated photographs intended for computer vision research. It has more
                            than 14 million images that capture different objects and indicate what they are, and in at least one million of the
                            images, bounding boxes are also provided.
                        </p>
                        <figure id="fig-1" class="kg-card kg-image-card kg-card-hascaption">
                            <img src="https://drive.google.com/uc?id=1TTSFVxUfX7Sed75tFKHDK5INo7A6gzDW"
                            class="kg-image lightense-target" alt="Model scaling for ConvNets" loading="lazy">
                            <figcaption>Figure 1. Model Scaling. (a) is a baseline network example; (b)-(d) are conventional scaling that only increases one
                                dimension of network width, depth, or resolution. (e) is the proposed compound scaling method that uniformly scales
                                all three dimensions with a fixed ratio by creators of EfficientNet</figcaption>
                        </figure>
                        <p>
                            When training model with more computational resources, we can either increase the network, width or resolution. The
                            factors (coefficients) can be determined by a small grid search on the original smaller model. <a class="text-cyan link link-underline" href="#fig-1">Figure 1</a> demonstrate
                            the difference between the compound scaling of the creators and other convetional methods.
                        </p>
                        <h3 id="optimization-problem" class="font-semibold">Optimization Problem</h3>
                        <p>
                            As the model scaling factor is quite complex yet still be one of the interesting of these researches, so I had tried
                            my best to make the explanation simpler.
                        </p>
                        <p>
                            First, the ConvNet Layer i can be defined with a function $$Y_i = F_i(X_i) \tag{1}\label{eq1}$$ where:
                            $$
                            \scriptsize{ 
                                \begin{array}{lll} \\
                                F_i     & = & \text{can be seen as the activation function used in that layer} \\
                                X_i     & = & \text{input tensor with shape $\langle$ H_i, W_i, C_i $\rangle$}   \\
                                Y_i     & = & \text{output tensor} \\
                                H_i, W_i & = & \text{spatial dimensions} \\
                                C_i     & = & \text{channel dimension}
                                \end{array}
                            }
                            $$
                        </p>
                        <p>
                            Then, a whole ConvNet $η$ is composed of layers with Hadamard Product (component-wise multiplication for matrices):
                            $$
                            \eta = F_k \odot ... \odot F_2 \odot F_1(X_1) = \odot_{j=1...k} F_j(X_1) \tag{2}\label{eq2}
                            $$
                        </p>
                        To explain the notation of equation $\eqref{eq2}$, the hadamard product can be described as the product of two 3x3 matrices below:
                        $$
                        \begin{bmatrix} a & b & c \\ d & e & f \\ g & h & i \end{bmatrix}\odot\begin{bmatrix} j & k & l \\ m & n & o \\ p & q &
                        r \end{bmatrix}= \begin{bmatrix} aj & bk & cl \\ dm & ne & fo \\ gp & hp & ir\end{bmatrix}
                        $$
                        <p>
                            In a network, the operation of layers are often repeated $L_i$ times in each stage, thus the general formula of η:
                            $$η = ⊙_{j = 1...s}F_i^{L_i}(X⟨H_i, W_i, C_i⟩) \tag{3}\label{eq3}$$
                        </p>
                        <p>
                            So far, we have know the formula that describe the architecture Fi. Most regular ConvNet designs focus on finding
                            the best $F_i$, meanwhile, the model scaling opt to change the network length ($L_i$), network width $(L_i)$, and/or
                            resolution ($H_i, W_i$) without changing $F_i$ predefined in the baseline network. However, by changing these factors, it
                            lead to the fact that a large design space will occurs in order to investigate different $L_i, C_i, H_i, W_i$ for each
                            layer.
                        </p>
                        <p>
                            <a class="text-cyan link link-underline" href="https://arxiv.org/abs/2104.00298"
                            rel="noopener noreferrer" target="_blank">Creators of EfficientNet</a>
                            came up with an idea that restrict all layers to be scaled up uniformly by a constant
                            ratio. Their target is to maximize the model accuracy for any given resources constraints, which can be described as
                            follow:
                        </p>
                        <figure id="fig-2" class="kg-card kg-image-card kg-card-hascaption">
                            <img src="https://drive.google.com/uc?id=1cDtqxUYokLAJ_6YBIHxwnx9tOk9ik82E"
                            class="kg-image lightense-target" alt="Formula with coefficients for optimization" loading="lazy">
                            <figcaption>Figure 2. Formula with coefficients for optimization
                            </figcaption>
                        </figure>
                        <p>
                            The <span style="color: yellow">yellow</span>, <span style="color: orange">orange</span> and <span style="color: rgb(115, 211, 255)">blue</span> rectangles are the scaling constants for the method, the white box will then take all
                            required parameters to form the formula, and the <span style="color: rgb(234, 122, 122)">red</span> rectangles represent for their target by applying the model
                            scaling. In next section, we will discuss some problems of this optimization problem.
                        </p>
                        <h3 id="scaling-dimension" class="font-semibold">Scaling Dimensions</h3>
                        <p>
                            As we have know that the formula from <a class="text-cyan link link-underline" href="#fig-2">Figure 2</a>, choosing
                            the optimal
                            parameters d, w, r is quite tricky since they depend on each other, and in some different resource constraints these
                            values may change. Therefore, the conventional method like <a class="text-cyan link link-underline"
                                href="#fig-1">Figure 1 (a), (b), (c), (d)</a> from mostly scale ConvNets in one of these dimensions, and here is
                            the table that sum-up the performance of each
                            way:

                            $$
                            \scriptsize{ 
                                \begin{array}{|c|c|c|}
                                \textbf{Dimension} & Pros & Cons \\\hline
                                \textbf{Depth (d)} & \text{- Capture richer & more complex features} & \text{- Face vanishing gradient problem} \\\hline
                                \textbf{Width (w)} & \displaylines{\text{- Capture more fine-grained features} \\ \text{- Easier to train}} & \displaylines{\displaylines{\text{- Hard to capture higher level feature} \\ \text{(wide but shallow network)}} \\ \text{- Face vanishing gradient problem}} \\\hline
                                \textbf{Resolution (r)} & \displaylines{\text{- Capture more fine-grained patterns} \\ \displaylines{\text{- Higher resolution means higher accuracy,} \\ \text{capable of achieves state-of-the-art}}} & \text{- Face vanishing gradient problem} \\\hline
                                \end{array}
                            }
                            $$
                        </p>
                        <p>
                            From their observation, the researchers conclude that "scaling up any dimension of network width, depth, or
                            resolution improves accuracy, but the accuracy gain diminishes for bigger models" (<i>EfficientNetV2: Smaller Models
                            and Faster Training</i>, 2020, p.4).
                        </p>
                        <h3 id="compound-scaling" class="font-semibold">Compound Scaling</h3>
                        <p>
                            In the later experiment, the researchers pointed out that balancing different dimensions scaling ratio would be
                            better than conventional single-dimension scaling. And to validate this point, they use different network depths and
                            resolutions, altogether with the width scaling. Results show that, by using width scaling without changing depth (d)
                            and resolution (r), the accuracy will be diminished.
                        </p>
                        <p>
                            However, with deeper d and higher resolution r, width scaling
                            method achieves better accuracy while maintaining the same Floating Point Operations Per Second (FLOPS) cost. As a
                            result, they gave a second point of view that "In order to pursue better accuracy and efficiency, it is critical to
                            balance all dimensions of network width, depth, and resolution during ConvNet scaling." (<i>EfficientNetV2: Smaller Models
                            and Faster Training</i>, 2020, p.4).
                        </p>
                        <p>
                            As said, the creators of EfficientNet proposed a new compound scaling method, which use a coefficient ϕ to uniformly
                            scales network width, depth and resolution:
                            $$
                            \begin{aligned}
                                depth: d = \alpha^\phi\\
                                width: w = \beta^\phi\\
                                resolution: r = \gamma^\phi
                            \end{aligned}
                            $$
                        </p>
                    </div>
                </article>
            </div>
        </main>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.0-beta1/dist/js/bootstrap.bundle.min.js" async defer
        integrity="sha384-pprn3073KE6tl6bjs2QrFaJGz5/SUsLqktiwsUTF55Jfv3qYSDhgCecCxMW52nD2" crossorigin="anonymous">
    </script>
        
</body>

</html>